{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"drop.txt\",\"r\") as file:\n",
    "    lines = file.readlines()\n",
    "lines = [line.strip() for line in lines]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abyss-actor-', 'acrobatic-magician', 'amazoness-golden-whip-master', 'amazoness-silver-sword-master', 'amorphage-envy', 'amorphage-gluttony', 'amorphage-goliath', 'amorphage-greed', 'amorphage-lechery', 'amorphage-pride', 'amorphage-sloth', 'amorphage-wrath', 'anchamoufrite', 'antihuman-intelligence-me-psy-ya', 'archfiend-eccentrick', 'burning-draw', 'bujin-hiruko', 'clock-arc', 'crystal-keeper', 'crystal-master', 'dark-doriado', 'd-d-ark', 'd-d-d-deviser', 'd-d-d-oblivion', 'd-d-dog', 'd-d-d-rebel', 'd-d-d-super', 'd-d-d-supersight', 'd-d-evil', 'd-d-gryphon', 'd-d-savant-galilei', 'd-d-savant-kepler', 'd-d-savant-nikola', 'd-d-savant-thomas', 'deskbot-005', 'deskbot-006', 'deskbot-007', 'deskbot-008', 'dharma-eye-magician', 'dinomight-powerload-the-dracoslayer', 'dinomist-ankylos', 'dinomist-brachion', 'dinomist-ceratops', 'dinomist-plesios', 'dinomist-pteran', 'dinomist-rex', 'dinomist-spinos', 'dinomist-stegosaur', 'double-or-nothing', 'dragodies-the-empowered-warrior', 'dragoncaller-magician', 'dragong', 'dragon-horn-hunter', 'dragon-horn-hunter-1', 'dragoons-of-draconia', 'dragoons-of-draconia-1', 'edge-imp-cotton-eater', 'fire-opal-head', 'flash-knight', 'foucault-s-cannon', 'fusion-recycling-plant', 'ghost-beef', 'gigathunter-giclops', 'guiding-ariadne', 'hallohallo', 'hallohallo-1', 'han-shi-kyudo-spirit', 'igknight-cavalier', 'igknight-crusader', 'igknight-gallant', 'igknight-margrave', 'igknight-paladin', 'igknight-squire', 'igknight-templar', 'igknight-veteran', 'ignis-phoenix-the-dracoslayer', 'kai-den-kendo-spirit', 'kuro-obi-karate-spirit', 'lancephorhynchus', 'lancephorhynchus-1', 'lector-pendulum-the-dracoverlord', 'lunalight-tiger', 'lunalight-wolf', 'luster-pendulum-the-dracoslayer', 'magical-abductor', 'magical-cavalry-of-cxulub', 'magical-cavalry-of-cxulub-1', 'magicalibra', 'majespecter-cat-nekomata', 'majespecter-crow-yata', 'majespecter-fox-kyubi', 'majespecter-raccoon-bunbuku', 'majespecter-toad-ogama', 'majespecter-unicorn-kirin', 'majesty-pegasus-the-dracoslayer', 'mandragon', 'master-pendulum-the-dracoslayer', 'mayosenju-hitot', 'metalfoes-goldriver', 'metalfoes-silverd', 'metalfoes-steelen', 'metalfoes-vanish', 'metalfoes-volflame', 'metaphys-decoy-dragon', 'metrognome', 'mild-turkey', 'mythical-beast-bashilisk', 'mythical-beast-garuda', 'mythical-beast-jackal', 'mythical-beast-jackal-king', 'mythical-beast-master-cerberus', 'mythical-beast-medusa', 'nirvana-high-paladin', 'odd-eyes-pendulum-dragon', 'odd-eyes-pendulumgraph-dragon', 'odd-eyes-raging-dragon', 'odd-eyes-rebellion-dragon', 'odd-eyes-revolution-dragon', 'odd-eyes-wing-dragon', 'pandora-s-jewelry-box', 'parametalfoes-azortless', 'parametalfoes-melcaster', 'patissciel-couverture', 'pazuzule', 'pendulumucho', 'performage-mirror-conductor', 'performage-plushfire', 'performapal-bit-bite-turtle', 'performapal-bubblebowwow', 'performapal-camelump', 'performapal-card-gardna', 'performapal-changeraffe', 'performapal-cheermole', 'performapal-coin-dragon', 'performapal-dag-daggerman', 'performapal-drummerilla', 'performapal-extra-slinger', 'performapal-fireflux', 'performapal-fire-mufflerlion', 'performapal-gentrude', 'performapal-gold-fang', 'performapal-gongato', 'performapal-guitartle', 'performapal-gumgumouton', 'performapal-handstandaccoon', 'performapal-kaleidoscorp', 'performapal-ladyange', 'performapal-laugh-maker', 'performapal-lebellman', 'performapal-lizardraw', 'performapal-monkeyboard', 'performapal-odd-eyes-light-phoenix', 'performapal-odd-eyes-unicorn', 'performapal-partnaga', 'performapal-pendulum-sorcerer', 'performapal-radish-horse', 'performapal-seal-eel', 'performapal-sellshell-crab', 'performapal-silver-claw', 'performapal-splashmammoth', 'performapal-trampolynx', 'performapal-trumpanda', 'performapal-trump-girl', 'performapal-trump-witch', 'performapal-witch', 'performapal-turn-toad', 'performapal-u-go-golem', 'performapal-whim-witch', 'piercing-moray', 'piercing-moray-1', 'predaplant-bufolicula', 'predaplant-triantis', 'qliphort-carrier', 'qliphort-cephalopod', 'qliphort-disk', 'qliphort-helix', 'qliphort-monolith', 'qliphort-scout', 'qliphort-shell', 'qliphort-stealth', 'rain-bozu', 'raremetalfoes-bismugear', 'rescue-hamster', 'risebell-the-summoner', 'ritual-beast-tamer-zeframpilica', 'ritual-beast-tamer-zefrawendi', 'saambell-the-star-bonder', 'samurai-cavalry-of-reptier', 'samurai-cavalry-of-reptier-1', 'satellarknight-zefrathuban', 'sea-dragoons-of-draconia', 'sea-dragoons-of-draconia-1', 'shaddoll-zefracore', 'shaddoll-zefranaga', 'sky-dragoons-of-draconia', 'sky-dragoons-of-draconia-1', 'speedroid-passinglider', 'steel-cavalry-of-dinon', 'steel-cavalry-of-dinon-1', 'stellarknight-zefraxciton', 'superheavy-samurai-general-coral', 'superheavy-samurai-general-jade', 'supreme-king-dragon-darkwurm', 'supreme-king-dragon-odd-eyes', 'supreme-king-gate-infinity', 'supreme-king-gate-zero', 'supreme-king-z-arc', 'symphonic-warrior-djj', 'symphonic-warrior-guitaar', 'symphonic-warrior-guitariss', 'symphonic-warrior-miccs', 'symphonic-warrior-rockks', 'timebreaker-magician', 'vector-pendulum-the-dracoverlord', 'xiangke-magician', 'xiangsheng-magician', 'yoko-zuna-sumo-spirit', 'zany-zebra', 'zefraath', 'zefraniu-secret-of-the-yang-zing', 'zefrasaber-swordmaster-of-the-nekroz', 'zefraxa-flame-beast-of-the-nekroz', 'zefraxi-treasure-of-the-yang-zing']\n"
     ]
    }
   ],
   "source": [
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "df=pd.read_csv('annotation.csv')[['file','card_name','card_id']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['file'].apply(lambda x: any(substring in x for substring in lines))\n",
    "df = df[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5092\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "# function to compute the hash of an image file\n",
    "def compute_hash(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        image_data = f.read()\n",
    "        return hashlib.sha256(image_data).hexdigest()\n",
    "\n",
    "df['file_path']=df['file'].apply(lambda x: 'C:/Users/PONNOU Wilfried/Desktop/Projet transverse/resized/'+x)\n",
    "# add a new column to the data frame with the hash of the image\n",
    "df['image_hash'] = df['file_path'].apply(compute_hash)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>card_name</th>\n",
       "      <th>card_id</th>\n",
       "      <th>file_path</th>\n",
       "      <th>image_hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spellbound.jpg</td>\n",
       "      <td>Spellbound</td>\n",
       "      <td>DABL-EN000</td>\n",
       "      <td>C:/Users/PONNOU Wilfried/Desktop/Projet transv...</td>\n",
       "      <td>f5325b8c102e10a5b8d4276dd8e73a4636b94091ceebb0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackwing-vata-the-emblem-of-wandering.jpg</td>\n",
       "      <td>Blackwing - Vata the Emblem of Wandering</td>\n",
       "      <td>DABL-EN001</td>\n",
       "      <td>C:/Users/PONNOU Wilfried/Desktop/Projet transv...</td>\n",
       "      <td>1c99bcf891dce90dc2cd729b58aef0dd86a524b1cebe86...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blackwing-shamal-the-sandstorm.jpg</td>\n",
       "      <td>Blackwing - Shamal the Sandstorm</td>\n",
       "      <td>DABL-EN002</td>\n",
       "      <td>C:/Users/PONNOU Wilfried/Desktop/Projet transv...</td>\n",
       "      <td>37b3139d79e0a1e64ff187b1d7a69db21ba9942a2208e1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blackwing-chinook-the-snow-blast.jpg</td>\n",
       "      <td>Blackwing - Chinook the Snow Blast</td>\n",
       "      <td>DABL-EN003</td>\n",
       "      <td>C:/Users/PONNOU Wilfried/Desktop/Projet transv...</td>\n",
       "      <td>c084b2334d83831a780761b3d33aa2a8b9fd9a3b79e97c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blackwing-sudri-the-phantom-glimmer.jpg</td>\n",
       "      <td>Blackwing - Sudri the Phantom Glimmer</td>\n",
       "      <td>DABL-EN004</td>\n",
       "      <td>C:/Users/PONNOU Wilfried/Desktop/Projet transv...</td>\n",
       "      <td>ca864ff348a6ccbb39d11212b06ac5a4b1e2dbe6712269...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         file  \\\n",
       "0                              spellbound.jpg   \n",
       "1  blackwing-vata-the-emblem-of-wandering.jpg   \n",
       "2          blackwing-shamal-the-sandstorm.jpg   \n",
       "3        blackwing-chinook-the-snow-blast.jpg   \n",
       "4     blackwing-sudri-the-phantom-glimmer.jpg   \n",
       "\n",
       "                                  card_name     card_id  \\\n",
       "0                                Spellbound  DABL-EN000   \n",
       "1  Blackwing - Vata the Emblem of Wandering  DABL-EN001   \n",
       "2          Blackwing - Shamal the Sandstorm  DABL-EN002   \n",
       "3        Blackwing - Chinook the Snow Blast  DABL-EN003   \n",
       "4     Blackwing - Sudri the Phantom Glimmer  DABL-EN004   \n",
       "\n",
       "                                           file_path  \\\n",
       "0  C:/Users/PONNOU Wilfried/Desktop/Projet transv...   \n",
       "1  C:/Users/PONNOU Wilfried/Desktop/Projet transv...   \n",
       "2  C:/Users/PONNOU Wilfried/Desktop/Projet transv...   \n",
       "3  C:/Users/PONNOU Wilfried/Desktop/Projet transv...   \n",
       "4  C:/Users/PONNOU Wilfried/Desktop/Projet transv...   \n",
       "\n",
       "                                          image_hash  \n",
       "0  f5325b8c102e10a5b8d4276dd8e73a4636b94091ceebb0...  \n",
       "1  1c99bcf891dce90dc2cd729b58aef0dd86a524b1cebe86...  \n",
       "2  37b3139d79e0a1e64ff187b1d7a69db21ba9942a2208e1...  \n",
       "3  c084b2334d83831a780761b3d33aa2a8b9fd9a3b79e97c...  \n",
       "4  ca864ff348a6ccbb39d11212b06ac5a4b1e2dbe6712269...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df,test_df = train_test_split(df, test_size=0.33, random_state=42, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3411\n"
     ]
    }
   ],
   "source": [
    "train_df.head()\n",
    "print(len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1681\n"
     ]
    }
   ],
   "source": [
    "test_df.head()\n",
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'train_data_cropped' created\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Leaf directory \n",
    "directory = \"train_data_cropped\"\n",
    "\n",
    "# Parent Directories \n",
    "parent_dir = \"C:/Users/PONNOU Wilfried/Desktop/Projet transverse\"\n",
    "\n",
    "# Path \n",
    "path = os.path.join(parent_dir, directory)\n",
    "\n",
    "# Create the directory \n",
    "# 'Nikhil' \n",
    "os.makedirs(path)\n",
    "print(\"Directory '% s' created\" % directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'train_cropped' created\n",
      "Copied\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from PIL import Image\n",
    "\n",
    "# Leaf directory \n",
    "train_directory = \"train_cropped\"\n",
    "\n",
    "# Parent Directories \n",
    "parent_dir = \"C:/Users/PONNOU Wilfried/Desktop/Projet transverse/train_data_cropped\"\n",
    "\n",
    "# Path \n",
    "path = os.path.join(parent_dir, train_directory)\n",
    "\n",
    "# Create the directory \n",
    "# 'Nikhil' \n",
    "os.makedirs(path)\n",
    "print(\"Directory '% s' created\" % train_directory)\n",
    "\n",
    "for img_path in train_df['file']:\n",
    "    src_path='./cropped/'+str(img_path)\n",
    "    img_final_path = os.path.join(path,img_path)\n",
    "    shutil.copy(src_path, img_final_path)\n",
    "print('Copied')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'test_cropped' created\n",
      "Copied\n"
     ]
    }
   ],
   "source": [
    "test_directory = \"test_cropped\"\n",
    "\n",
    "# Parent Directories \n",
    "parent_dir = \"C:/Users/PONNOU Wilfried/Desktop/Projet transverse/train_data_cropped\"\n",
    "\n",
    "# Path \n",
    "path = os.path.join(parent_dir, test_directory)\n",
    "\n",
    "# Create the directory \n",
    "# 'Nikhil' \n",
    "os.makedirs(path)\n",
    "print(\"Directory '% s' created\" % test_directory)\n",
    "\n",
    "for img_path in test_df['file']:\n",
    "    src_path='./cropped/'+str(img_path)\n",
    "    img_final_path = os.path.join(path,img_path)\n",
    "    shutil.copy(src_path, img_final_path)\n",
    "print('Copied')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.reset_index(inplace=True)\n",
    "train_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_point_annnotation_cropped.txt','w') as f:\n",
    "    for i in range(len(test_df)):\n",
    "        f.write(\"test_cropped/\"+str(test_df['file'][i])+\"\\t\"+'[{\"transcription\": \"'+str(test_df['card_id'][i])+'\", \"points\": [[400, 710], [400, 750], [545, 750], [545, 710]]}]'+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_point_annnotation_cropped.txt','w') as f:\n",
    "    for i in range(len(train_df)):\n",
    "        f.write(\"train_cropped/\"+str(train_df['file'][i])+\"\\t\"+'[{\"transcription\": \"'+str(train_df['card_id'][i])+'\", \"points\": [[400, 710], [400, 750], [545, 750], [545, 710]]}]'+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_data_cropped/test_annnotation_cropped.txt','w') as f:\n",
    "    for i in range(len(test_df)):\n",
    "        f.write(\"test_cropped/\"+str(test_df['file'][i])+'\\t'+str(test_df['card_id'][i])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_data_cropped/train_annnotation_cropped.txt','w') as f:\n",
    "    for i in range(len(train_df)):\n",
    "        f.write(\"train_cropped/\"+str(train_df['file'][i])+\"\\t\"+str(train_df['card_id'][i])+'\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sary dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sary = df.rename(columns={'file': 'filename',\n",
    "                        'card_id': 'words'})\n",
    "df_sary=df_sary[['filename','words']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spellbound.jpg</td>\n",
       "      <td>DABL-EN000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackwing-vata-the-emblem-of-wandering.jpg</td>\n",
       "      <td>DABL-EN001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blackwing-shamal-the-sandstorm.jpg</td>\n",
       "      <td>DABL-EN002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blackwing-chinook-the-snow-blast.jpg</td>\n",
       "      <td>DABL-EN003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blackwing-sudri-the-phantom-glimmer.jpg</td>\n",
       "      <td>DABL-EN004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     filename       words\n",
       "0                              spellbound.jpg  DABL-EN000\n",
       "1  blackwing-vata-the-emblem-of-wandering.jpg  DABL-EN001\n",
       "2          blackwing-shamal-the-sandstorm.jpg  DABL-EN002\n",
       "3        blackwing-chinook-the-snow-blast.jpg  DABL-EN003\n",
       "4     blackwing-sudri-the-phantom-glimmer.jpg  DABL-EN004"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df_sary,test_df_sary = train_test_split(df_sary, test_size=0.33, random_state=42, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'train_sary' created\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Leaf directory \n",
    "directory = \"train_sary\"\n",
    "\n",
    "# Parent Directories \n",
    "parent_dir = \"C:/Users/PONNOU Wilfried/Desktop/Projet transverse\"\n",
    "\n",
    "# Path \n",
    "path = os.path.join(parent_dir, directory)\n",
    "\n",
    "# Create the directory \n",
    "# 'Nikhil' \n",
    "os.makedirs(path)\n",
    "print(\"Directory '% s' created\" % directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'train_data' created\n",
      "Copied\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from PIL import Image\n",
    "\n",
    "# Leaf directory \n",
    "train_directory = \"train_data\"\n",
    "\n",
    "# Parent Directories \n",
    "parent_dir = \"C:/Users/PONNOU Wilfried/Desktop/Projet transverse/train_sary\"\n",
    "\n",
    "# Path \n",
    "path = os.path.join(parent_dir, train_directory)\n",
    "\n",
    "# Create the directory \n",
    "# 'Nikhil' \n",
    "os.makedirs(path)\n",
    "print(\"Directory '% s' created\" % train_directory)\n",
    "\n",
    "for img_path in train_df_sary['filename']:\n",
    "    src_path='./cropped/'+str(img_path)\n",
    "    img_final_path = os.path.join(path,img_path)\n",
    "    shutil.copy(src_path, img_final_path)\n",
    "print('Copied')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_sary.to_csv('train_sary/train_data/labels.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'en_val' created\n",
      "Copied\n"
     ]
    }
   ],
   "source": [
    "test_directory = \"en_val\"\n",
    "\n",
    "# Parent Directories \n",
    "parent_dir = \"C:/Users/PONNOU Wilfried/Desktop/Projet transverse/train_sary\"\n",
    "\n",
    "# Path \n",
    "path = os.path.join(parent_dir, test_directory)\n",
    "\n",
    "# Create the directory \n",
    "# 'Nikhil' \n",
    "os.makedirs(path)\n",
    "print(\"Directory '% s' created\" % test_directory)\n",
    "\n",
    "for img_path in test_df_sary['filename']:\n",
    "    src_path='./cropped/'+str(img_path)\n",
    "    img_final_path = os.path.join(path,img_path)\n",
    "    shutil.copy(src_path, img_final_path)\n",
    "print('Copied')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_sary.to_csv('train_sary/en_val/labels.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "img = Image.open(\"abominable-unchained-soul.jpg\")\n",
    "newsize = (320, 48)\n",
    "im1 = img.resize(newsize,resample=Image.Resampling.LANCZOS)\n",
    "im1.save(\"abominable-unchained-soul-bis.jpg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOCTR DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'train_doctr' created\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Leaf directory \n",
    "directory = \"train_doctr\"\n",
    "\n",
    "# Parent Directories \n",
    "parent_dir = \"C:/Users/PONNOU Wilfried/Desktop/Projet transverse\"\n",
    "\n",
    "# Path \n",
    "path = os.path.join(parent_dir, directory)\n",
    "\n",
    "# Create the directory \n",
    "# 'Nikhil' \n",
    "os.makedirs(path)\n",
    "print(\"Directory '% s' created\" % directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'train_recognition/images' created\n",
      "Copied\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from PIL import Image\n",
    "\n",
    "# Leaf directory \n",
    "train_directory = \"train_recognition/images\"\n",
    "\n",
    "# Parent Directories \n",
    "parent_dir = \"C:/Users/PONNOU Wilfried/Desktop/Projet transverse/train_doctr\"\n",
    "\n",
    "# Path \n",
    "path = os.path.join(parent_dir, train_directory)\n",
    "\n",
    "# Create the directory \n",
    "# 'Nikhil' \n",
    "os.makedirs(path)\n",
    "print(\"Directory '% s' created\" % train_directory)\n",
    "\n",
    "for img_path in train_df['file']:\n",
    "    src_path='./cropped/'+str(img_path)\n",
    "    img_final_path = os.path.join(path,img_path)\n",
    "    shutil.copy(src_path, img_final_path)\n",
    "print('Copied')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'test_recognition/images' created\n",
      "Copied\n"
     ]
    }
   ],
   "source": [
    "test_directory = \"test_recognition/images\"\n",
    "\n",
    "# Parent Directories \n",
    "parent_dir = \"C:/Users/PONNOU Wilfried/Desktop/Projet transverse/train_doctr\"\n",
    "\n",
    "# Path \n",
    "path = os.path.join(parent_dir, test_directory)\n",
    "\n",
    "# Create the directory \n",
    "# 'Nikhil' \n",
    "os.makedirs(path)\n",
    "print(\"Directory '% s' created\" % test_directory)\n",
    "\n",
    "for img_path in test_df['file']:\n",
    "    src_path='./cropped/'+str(img_path)\n",
    "    img_final_path = os.path.join(path,img_path)\n",
    "    shutil.copy(src_path, img_final_path)\n",
    "print('Copied')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    " \n",
    "import pandas as pd\n",
    "\n",
    "# create dictionary from data frame\n",
    "dict_from_df = train_df.set_index('file')['card_id'].to_dict()\n",
    "\n",
    "\n",
    "# Serializing json\n",
    "json_object = json.dumps(dict_from_df, indent=4)\n",
    " \n",
    "# Writing to sample.json\n",
    "with open(\"C:/Users/PONNOU Wilfried/Desktop/Projet transverse/train_doctr/train_recognition/labels.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    " \n",
    "import pandas as pd\n",
    "\n",
    "# create dictionary from data frame\n",
    "dict_from_df = test_df.set_index('file')['card_id'].to_dict()\n",
    "\n",
    "\n",
    "# Serializing json\n",
    "json_object = json.dumps(dict_from_df, indent=4)\n",
    " \n",
    "# Writing to sample.json\n",
    "with open(\"C:/Users/PONNOU Wilfried/Desktop/Projet transverse/train_doctr/test_recognition/labels.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'train_detection/images' created\n",
      "Copied\n"
     ]
    }
   ],
   "source": [
    "# Leaf directory \n",
    "train_directory = \"train_detection/images\"\n",
    "\n",
    "# Parent Directories \n",
    "parent_dir = \"C:/Users/PONNOU Wilfried/Desktop/Projet transverse/train_doctr\"\n",
    "\n",
    "# Path \n",
    "path = os.path.join(parent_dir, train_directory)\n",
    "\n",
    "# Create the directory \n",
    "# 'Nikhil' \n",
    "os.makedirs(path)\n",
    "print(\"Directory '% s' created\" % train_directory)\n",
    "\n",
    "for img_path in train_df['file']:\n",
    "    src_path='./resized/'+str(img_path)\n",
    "    img_final_path = os.path.join(path,img_path)\n",
    "    shutil.copy(src_path, img_final_path)\n",
    "print('Copied')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'test_detection/images' created\n",
      "Copied\n"
     ]
    }
   ],
   "source": [
    "test_directory = \"test_detection/images\"\n",
    "\n",
    "# Parent Directories \n",
    "parent_dir = \"C:/Users/PONNOU Wilfried/Desktop/Projet transverse/train_doctr\"\n",
    "\n",
    "# Path \n",
    "path = os.path.join(parent_dir, test_directory)\n",
    "\n",
    "# Create the directory \n",
    "# 'Nikhil' \n",
    "os.makedirs(path)\n",
    "print(\"Directory '% s' created\" % test_directory)\n",
    "\n",
    "for img_path in test_df['file']:\n",
    "    src_path='./resized/'+str(img_path)\n",
    "    img_final_path = os.path.join(path,img_path)\n",
    "    shutil.copy(src_path, img_final_path)\n",
    "print('Copied')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dictionary\n",
    "d_train_detection = {}\n",
    "for i, row in train_df.iterrows():\n",
    "    file_name = row['file']\n",
    "    img_hash = row['image_hash']\n",
    "    d_train_detection[file_name] = {\n",
    "        'img_dimensions': (600,1000),\n",
    "        'img_hash': img_hash,\n",
    "        'polygons': [[[400, 710], [545, 710], [545, 750], [400, 750]]]\n",
    "    }\n",
    "# Serializing json\n",
    "json_object = json.dumps(d_train_detection, indent=4)\n",
    " \n",
    "# Writing to sample.json\n",
    "with open(\"C:/Users/PONNOU Wilfried/Desktop/Projet transverse/train_doctr/train_detection/labels.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dictionary\n",
    "d_test_detection = {}\n",
    "for i, row in test_df.iterrows():\n",
    "    file_name = row['file']\n",
    "    img_hash = row['image_hash']\n",
    "    d_test_detection[file_name] = {\n",
    "        'img_dimensions': (600,1000),\n",
    "        'img_hash': img_hash,\n",
    "        'polygons': [[[400, 710], [545, 710], [545, 750], [400, 750]]]\n",
    "    }\n",
    "# Serializing json\n",
    "json_object = json.dumps(d_test_detection, indent=4)\n",
    " \n",
    "# Writing to sample.json\n",
    "with open(\"C:/Users/PONNOU Wilfried/Desktop/Projet transverse/train_doctr/test_detection/labels.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5de91d4c2035e3a5d94b0416f3d9b06d53541789080bfc7f25065bc5d777d64d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
